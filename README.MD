# Safe for Work Classifier

This repository contains code for training a Safe for Work (SFW) classifier on Malaysian data. The classifier is designed to detect various categories including hate speech, violence, self-harm, harassment, informative content, psychiatric or mental illness-related content, racist speech, religion insults, sexist speech, pornographic content, and content that is safe for work.


Finetuned https://huggingface.co/mesolitica/malaysian-mistral-191M-MLM-512 with Malaysian NSFW data.


## Methodology


## LLMOps Pipeline

![Image in a markdown cell](https://github.com/mesolitica/malaysian-llmops/raw/main/e2e.png)


## How to Use




